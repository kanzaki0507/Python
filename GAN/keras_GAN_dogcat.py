# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cKTA-ExGQC09n2Ah1fJhey-ZflSuv3uI
"""
# Googleドライブではhomeがcontentなのでpathをマウントする

from google.colab import drive
drive.mount('/content/drive')

# Google colavoratoryで実行しないと動かない(GPU)
import numpy as np
import glob
import keras
from keras.preprocessing.image import img_to_array, load_img
import pdb
from sklearn.model_selection import train_test_split
from keras.datasets import mnist
from keras.applications.vgg16 import VGG16
from keras.layers import Input
from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Activation, Flatten, BatchNormalization, Reshape, UpSampling2D, GlobalAveragePooling2D
from tqdm import tqdm
from keras.models import Sequential, Model
from keras.applications.inception_v3 import InceptionV3

import os

img_h = 32
img_w = 32

# Generatorモデルを定義
def G_model(Height, Width, channel=3):
    inputs = Input((100,))
    in_h = int(Height / 4)
    in_w = int(Width / 4)
    x = Dense(in_h * in_w * 128, activation='tanh', name='g_dense1')(inputs)
    x = BatchNormalization()(x)
    x = Reshape((in_h, in_w, 128), input_shape=(128 * in_h * in_w,))(x)
    x = UpSampling2D(size=(2, 2))(x)
    x = Conv2D(64, (5, 5), padding='same', activation='tanh', name='g_conv1')(x)
    x = UpSampling2D(size=(2, 2))(x)
    x = Conv2D(channel, (5, 5), padding='same', activation='tanh', name='g_out')(x)
    model = Model(inputs, x, name='G')
    return model

# Discriminatorのモデルを定義
def D_model(Height, Width, channel=3):
    inputs = Input((Height, Width, channel))
    x = Conv2D(64, (5, 5), padding='same', activation='tanh', name='d_conv1')(inputs)
    x = MaxPooling2D(pool_size=(2, 2))(x)
    x = Conv2D(128, (5, 5), padding='same', activation='tanh', name='d_conv2')(x)
    x = MaxPooling2D(pool_size=(2, 2))(x)
    x = Flatten()(x)
    x = Dense(1024, activation='relu', name='d_dense1')(x)
    x = Dense(1, activation='sigmoid', name='d_out')(x)
    model = Model(inputs, x, name='D')
    return model

# GとDモデルを結合
def Combined_model(g, d):
    model = Sequential()
    model.add(g)
    model.add(d)
    return model

  
g = G_model(Height=img_h, Width=img_w, channel=3)
d = D_model(Height=img_h, Width=img_w, channel=3)
c = Combined_model(g=g, d=d)

g_opt = keras.optimizers.Adam(lr=0.0002, beta_1=0.5)
d_opt = keras.optimizers.Adam(lr=0.0002, beta_1=0.5)

g.compile(loss='binary_crossentropy', optimizer='SGD')
d.trainable = False
for layer in d.layers:
    layer.trainable = False
c.compile(loss='binary_crossentropy', optimizer=g_opt)

d.trainable = True
for layer in d.layers:
    layer.trainable = True
d.compile(loss='binary_crossentropy', optimizer=d_opt)


# 犬と猫の画像を読み込む
# pathを指定
file_list = glob.glob('/content/drive/My Drive/機械学習/figs/*/*.jpg')
print(file_list)

X = [] # 画像データを保存する変数
Y = [] # ラベルを保存する変数



for file in file_list:
    print(file)
    # 画像処理
    img = img_to_array(load_img(file, grayscale=False, color_mode='rgb', target_size=(img_h, img_w)))
    X.append(img)

    # label処理
    #split_file = file.split('/')
    #print(split_file)

    if 'dogs' in file:
        Y.append(0)
    else:
        Y.append(1)

    # pdb.set_trace()

X = np.asarray(X)
print(X.shape, X.max(), X.min(), X.dtype)

Y = np.asarray(Y)
print(Y.shape, Y.dtype, Y)
# 訓練とテストを読み込む
# X_train: 訓練画像, Y_train: 訓練ラベル, X_test: テスト画像, Y_test: テストラベル
x_train, x_test, y_train, y_test = train_test_split(X, Y, train_size=0.8)
# print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)


# 正規化
x_train = (x_train.astype(np.float32) - 127.5)/127.5
# x_train = (x_train.astype(np.float32))/255.0
# チャンネルを無理やりつくている
#print(x_train.shape)
# x_train = x_train[:, :, :, None]
#print(x_train.shape)

train_num = x_train.shape[0]
train_num_per_step = train_num // 2

# ミニバッチを定義
Minibatch = 2

for ite in tqdm(range(1000)):
    ite += 1
    # Discremenator training
    train_ind = ite % (train_num_per_step - 1)
    y = x_train[train_ind * Minibatch: (train_ind+1) * Minibatch]
    input_noise = np.random.uniform(-1, 1, size=(Minibatch, 100))
    g_output = g.predict(input_noise, verbose=0)
    #print(y.shape, g_output.shape)
    X = np.concatenate((y, g_output))
    Y = [1] * Minibatch + [0] * Minibatch
    #print(X.shape, len(Y))
    d_loss = d.train_on_batch(X, Y)

    # Generator training
    input_noise = np.random.uniform(-1, 1, size=(Minibatch, 100))
    g_loss = c.train_on_batch(input_noise, [1] * Minibatch)

import matplotlib.pyplot as plt

def save_images(imgs, index, dir_path):
    # Argment
    #  img_batch = np.array((batch, height, width, channel)) with value range [-1, 1]
    B, H, W, C = imgs.shape
    batch= imgs * 127.5 + 127.5
    batch = batch.astype(np.uint8)
    w_num = np.ceil(np.sqrt(B)).astype(np.int)
    h_num = int(np.ceil(B / w_num))
    out = np.zeros((h_num*H, w_num*W), dtype=np.uint8)
    for i in range(B):
        x = i % w_num
        y = i // w_num
        out[y*H:(y+1)*H, x*W:(x+1)*W] = batch[i, ..., 0]
    fname = str(index).zfill(len(str(3000))) + '.jpg'
    save_path = os.path.join(dir_path, fname)

    plt.imshow(out)
    plt.title("iteration: {}".format(index))
    plt.axis("off")
    plt.savefig(save_path)

save_images(g_output, index=1000, dir_path='./')

